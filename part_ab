            audit_record(
                action="metrics_error",
                actor="admin",
                subject=f"metrics:{participant_id}",
                status="error",
                extra={"error": str(e)}
            )
        except:
            pass
        return jsonify({"ok": False, "error": "metrics_failed"}), 500


import hashlib
import shutil
from flask import send_file

# ---------- Participant export + erase endpoints (D3) ----------
# Place this after your /snare route

def _read_jsonl_file(path):
    """Yield parsed JSON objects from a jsonl file (skip broken lines)."""
    import json
    try:
        with open(path, "r", encoding="utf-8") as fh:
            for line in fh:
                line = line.strip()
                if not line:
                    continue
                try:
                    yield json.loads(line)
                except Exception:
                    # skip malformed lines
                    continue
    except FileNotFoundError:
        return
    except PermissionError:
        return

def _collect_participant_records(participant_id):
    """Collect records mentioning participant_id from known log files."""
    files_to_scan = []
    # adjust these names if your module uses different constants
    try:
        files_to_scan = [AUDIT_LOG, CONSENT_LOG, DATA_LOG]
    except Exception:
        # fallback to logs by path if constants missing
        files_to_scan = ["logs/audit_log.jsonl", "logs/consent_log.jsonl", "logs/data_log.jsonl"]

    out = []
    for path in files_to_scan:
        for obj in _read_jsonl_file(path):
            # some logs embed participant_id at top-level or inside 'actor' etc.
            if not isinstance(obj, dict):
                continue
            # quick checks for participant id in common fields
            if obj.get("participant_id") == participant_id:
                out.append({"file": path, "record": obj})
                continue
            # actor might include "participant:xxxx"
            actor = obj.get("actor", "")
            if isinstance(actor, str) and actor.endswith(participant_id):
                out.append({"file": path, "record": obj})
                continue
            # nested extra fields often contain participant_id
            extra = obj.get("extra", {})
            if isinstance(extra, dict) and extra.get("participant_id") == participant_id:
                out.append({"file": path, "record": obj})
                continue
            # a loose search across values
            if any(str(v) == participant_id for v in obj.values()):
                out.append({"file": path, "record": obj})
    return out


@app.route("/admin/export/<participant_id>", methods=["GET"])
@admin_required
def export_participant(participant_id):
    """
    Admin endpoint: export all records for a participant_id as JSON.
    """
    try:
        records = _collect_participant_records(participant_id)
        # record the export action in the audit log
        try:
            audit_record(action="export_requested", actor="admin", subject=f"export:{participant_id}", status="ok", extra={"matches": len(records)})
        except Exception:
            pass

        return jsonify({"ok": True, "participant_id": participant_id, "matches": len(records), "records": records}), 200
    except Exception as e:
        try:
            audit_record(action="export_failed", actor="admin", subject=f"export:{participant_id}", status="error", extra={"error": str(e)})
        except Exception:
            pass
        return jsonify({"ok": False, "error": "export_failed"}), 500


def _anonymize_and_replace_in_file(path, participant_id, replacement_token):
    """
    Read path, write a temp file with participant_id replaced by replacement_token,
    then atomically move the temp file over original (after backup).
    Returns number of lines changed.
    """
    import json, tempfile, os
    changed = 0
    tmp_fd, tmp_path = tempfile.mkstemp(prefix="rewrite_", dir=".")
    os.close(tmp_fd)
    try:
        with open(path, "r", encoding="utf-8") as rf, open(tmp_path, "w", encoding="utf-8") as wf:
            for line in rf:
                if participant_id in line:
                    # attempt safe json load/modify/write, otherwise do text replace
                    try:
                        obj = json.loads(line)
                        modified = False
                        # replace in top-level participant_id if present
                        if obj.get("participant_id") == participant_id:
                            obj["participant_id"] = replacement_token
                            modified = True
                        # replace in actor if matches
                        actor = obj.get("actor")
                        if isinstance(actor, str) and actor.endswith(participant_id):
                            obj["actor"] = actor.replace(participant_id, replacement_token)
                            modified = True
                        # replace in extras recursively (shallow)
                        extra = obj.get("extra", {})
                        if isinstance(extra, dict) and extra.get("participant_id") == participant_id:
                            extra["participant_id"] = replacement_token
                            obj["extra"] = extra
                            modified = True
                        if modified:
                            wf.write(json.dumps(obj, separators=(",", ":"), ensure_ascii=False) + "\n")
                            changed += 1
                            continue
                    except Exception:
                        # fallback to text replace
                        new_line = line.replace(participant_id, replacement_token)
                        if new_line != line:
                            changed += 1
                        wf.write(new_line)
                        continue
                wf.write(line)
    except FileNotFoundError:
        # nothing to do if file missing
        try:
            os.remove(tmp_path)
        except Exception:
            pass
        return 0
    # backup original (timestamped)
    try:
        bak_path = f"{path}.bak-{int(time.time())}"
        shutil.copy2(path, bak_path)
        # replace file atomically
        shutil.move(tmp_path, path)
    except Exception:
        # cleanup tmp if move failed
        try:
            os.remove(tmp_path)
        except Exception:
            pass
        raise
    return changed


@app.route("/admin/erase/<participant_id>", methods=["POST"])
@admin_required
def erase_participant_admin(participant_id):
    """
    Admin endpoint to anonymize a participant's identifiers in logs.
    Replaces direct participant_id with anonymized:<hash>.
    Note: This is a best-effort pseudonymization that keeps records but removes the clear identifier.
    """
    try:
        # create a deterministic pseudonym to keep ability to link anonymized records
        h = hashlib.sha256(participant_id.encode("utf-8")).hexdigest()[:16]
        replacement = f"anonymized:{h}"
        files_to_scan = []
        try:
            files_to_scan = [AUDIT_LOG, CONSENT_LOG, DATA_LOG]
        except Exception:
            files_to_scan = ["logs/audit_log.jsonl", "logs/consent_log.jsonl", "logs/data_log.jsonl"]

        total_changed = 0
        for path in files_to_scan:
            try:
                changed = _anonymize_and_replace_in_file(path, participant_id, replacement)
                total_changed += changed
            except Exception as e:
                # log failure in audit log but continue
                try:
                    audit_record(action="erase_partial_fail", actor="admin", subject=f"erase:{participant_id}", status="error", extra={"path": path, "error": str(e)})
                except Exception:
                    pass

        # final audit record for the erase action
        try:
            audit_record(action="erase_performed", actor="admin", subject=f"erase:{participant_id}", status="ok", extra={"replacement": replacement, "changed_lines": total_changed})
        except Exception:
            pass

        return jsonify({"ok": True, "participant_id": participant_id, "replacement": replacement, "changed_lines": total_changed}), 200
    except Exception as e:
        try:
            audit_record(action="erase_failed", actor="admin", subject=f"erase:{participant_id}", status="error", extra={"error": str(e)})
        except Exception:
            pass
        return jsonify({"ok": False, "error": "erase_failed"}), 500


@app.route("/erase", methods=["POST"])
def erase_participant_self():
    """
    Participant-initiated erase: requires a participant cookie (participant_id).
    This endpoint anonymizes that participant's records (same strategy as admin erase).
    """
    try:
        part = request.cookies.get("participant_id")
        if not part:
            return jsonify({"ok": False, "error": "no_participant_cookie"}), 400
        # delegate to admin-style erasure (use same replacement)
        # (we don't require admin token here because it's a user self-erase)
        h = hashlib.sha256(part.encode("utf-8")).hexdigest()[:16]
        replacement = f"anonymized:{h}"
        files_to_scan = []
        try:
            files_to_scan = [AUDIT_LOG, CONSENT_LOG, DATA_LOG]
        except Exception:
            files_to_scan = ["logs/audit_log.jsonl", "logs/consent_log.jsonl", "logs/data_log.jsonl"]

        total_changed = 0
        for path in files_to_scan:
            try:
                changed = _anonymize_and_replace_in_file(path, part, replacement)
                total_changed += changed
            except Exception:
                pass

        try:
            audit_record(action="erase_self", actor=f"participant:{part}", subject=f"erase:self", status="ok", extra={"replacement": replacement, "changed_lines": total_changed})
        except Exception:
            pass

        return jsonify({"ok": True, "replacement": replacement, "changed_lines": total_changed}), 200
    except Exception as e:
        try:
            audit_record(action="erase_self_failed", actor="unknown", subject="/erase", status="error", extra={"error": str(e)})
        except Exception:
            pass
        return jsonify({"ok": False, "error": "erase_failed"}), 500

# End D3 endpoints

# ---- Admin dashboard (Phase4 - D1) ----
from flask import send_from_directory, url_for
@app.route("/admin/dashboard", methods=["GET"])
@admin_required
def admin_dashboard():
    # small summary counts (use your existing constants or compute)
    try:
        counts = {
            "audit_log_lines": sum(1 for _ in _read_jsonl_file(AUDIT_LOG)) if 'AUDIT_LOG' in globals() else None,
            "consent_log_lines": sum(1 for _ in _read_jsonl_file(CONSENT_LOG)) if 'CONSENT_LOG' in globals() else None,
            "data_log_lines": sum(1 for _ in _read_jsonl_file(DATA_LOG)) if 'DATA_LOG' in globals() else None,
            "sessions": len(session_data()) if 'session_data' in globals() else None
        }
    except Exception:
        counts = {"audit_log_lines": None, "consent_log_lines": None, "data_log_lines": None, "sessions": None}

    # sample recent events: tail of audit_log (best-effort)
    recent = []
    try:
        for obj in list(_read_jsonl_file(AUDIT_LOG or "logs/audit_log.jsonl"))[-10:]:
            recent.append({
                "ts": obj.get("ts"),
                "action": obj.get("action"),
                "actor": obj.get("actor"),
                "subject": obj.get("subject")
            })
    except Exception:
        recent = []

    return render_template("admin_dashboard.html", counts=counts, recent=recent)


# --------------------------
#  ADMIN TOKEN HELPERS (Section 1)
# --------------------------
def get_admin_token() -> str:
    """Always read the current admin token from env to support live rotation."""
    return os.environ.get("ADMIN_TOKEN", "").strip()

def extract_admin_token_from_request() -> str:
    """Accept Authorization: Bearer <token> or X-ADMIN-TOKEN: <token> (or raw Authorization)."""
    auth = request.headers.get("Authorization", "")
    if auth.startswith("Bearer "):
        return auth.split(" ", 1)[1].strip()
    return (request.headers.get("X-ADMIN-TOKEN", "").strip()
            or auth.strip())

# ---- Admin export download (Phase 4 - D2) ----
from flask import send_file
import json
import tempfile
import os

@app.route("/admin/download/<participant_id>", methods=["GET"])
@admin_required
def admin_download(participant_id):
    """
    Download the exported JSON for a participant.
    This wraps the data into a temporary file and returns it.
    """
    try:
        # reuse your D3 export helper
        records = _collect_participant_records(participant_id)

        # create temp file
        tmp_fd, tmp_path = tempfile.mkstemp(prefix=f"export-{participant_id}-", suffix=".json")
        os.close(tmp_fd)

        with open(tmp_path, "w", encoding="utf-8") as f:
            json.dump({
                "ok": True,
                "participant_id": participant_id,
                "matches": len(records),
                "records": records
            }, f, indent=2, ensure_ascii=False)

        # send as file
        return send_file(
            tmp_path,
            mimetype="application/json",
            as_attachment=True,
            download_name=f"export-{participant_id}.json"
        )

    except Exception as e:
        try:
            audit_record(
                action="export_download_failed",
                actor="admin",
                subject=f"download:{participant_id}",
                status="error",
                extra={"error": str(e)}
            )
        except Exception:
            pass
        
        return jsonify({"ok": False, "error": "download_failed"}), 500


# --------------------------
#  APP INITIALIZATION
# --------------------------

# Guardrail 2: Limit max request body to 1 MB
app.config["MAX_CONTENT_LENGTH"] = 1 * 1024 * 1024


CONSENT_VERSION = "v1.0"
CORRECT_ANSWER = "23"  # change logic later if needed

# Folder setup
BASE_DIR = os.path.dirname(__file__)
LOG_DIR = os.path.join(BASE_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

CONSENT_LOG = os.path.join(LOG_DIR, "consent_log.jsonl")
DATA_LOG = os.path.join(LOG_DIR, "data_log.jsonl")
AUDIT_LOG = os.path.join(LOG_DIR, "audit_log.jsonl")

# Set admin token via environment
def get_admin_token():
    # Primary: environment
    token = os.environ.get("ADMIN_TOKEN")
    if token:
        return token.strip()

    # Secondary: optional file fallback
    token_path = os.environ.get("ADMIN_TOKEN_FILE") or os.path.join(LOG_DIR, "admin_token.txt")
    try:
        with open(token_path, "r", encoding="utf-8") as f:
            token = f.read().strip()
            return token or None
    except Exception:
        return None

# --------------------------
#  UTILITIES
# --------------------------
# ---------- Secure JSONL logging with rotation + tamper-evident chain ----------

def _lim(val, default):
    try:
        return int(val)
    except Exception:
        return default

LOG_MAX_BYTES = _lim(os.environ.get("LOG_MAX_BYTES", 512 * 1024), 512 * 1024)  # 512 KB default
LOG_BACKUPS   = _lim(os.environ.get("LOG_BACKUPS", 5), 5)                     # keep 5 backups
LOG_HMAC_KEY_HEX = os.environ.get("LOG_HMAC_KEY", "").strip()                 # set to random hex for tamper-evidence

def _rotate_file_if_needed(path: str):
    try:
        if not os.path.exists(path):
            return
        if os.path.getsize(path) <= LOG_MAX_BYTES:
            return
        # rotate: .4 -> .5, .3 -> .4, ... path -> .1
        for i in range(LOG_BACKUPS, 0, -1):
            src = f"{path}.{i}" if i > 1 else path
            dst = f"{path}.{i+1}" if i > 0 else None
            if os.path.exists(src):
                if i == LOG_BACKUPS:
                    try:
                        os.remove(f"{path}.{LOG_BACKUPS+1}")
                    except Exception:
                        pass
                os.rename(src, f"{path}.{i+1}")
        # create fresh file
        open(path, "a", encoding="utf-8").close()
    except Exception as e:
        # last resort: don't crash app because rotation failed
        print(f"[WARN] rotation failed for {path}: {e}")

def _last_chain_hmac(path: str) -> str | None:
    """Read last JSONL line's _h value to chain HMACs; return None if unavailable."""
    if not os.path.exists(path):
        return None
    try:
        with open(path, "rb") as f:
            f.seek(0, os.SEEK_END)
            size = f.tell()
            # read from the end in small chunk
            step = min(4096, size)
            f.seek(max(0, size - step))
            tail = f.read().decode("utf-8", errors="ignore")
        lines = [ln for ln in tail.strip().splitlines() if ln.strip()]
        if not lines:
            return None
        last = lines[-1]
        try:
            j = json.loads(last)
            return j.get("_h")
        except Exception:
            return None
    except Exception:
        return None

def _sign_line(payload_bytes: bytes, prev_h: str | None) -> str | None:
    """Return hex HMAC over (prev_h||payload) if LOG_HMAC_KEY_HEX is set."""
    if not LOG_HMAC_KEY_HEX:
        return None
    try:
        key = bytes.fromhex(LOG_HMAC_KEY_HEX)
    except ValueError:
        return None
    hm = hmac.new(key, digestmod=hashlib.sha256)
    if prev_h:
        hm.update(prev_h.encode("utf-8"))
    hm.update(payload_bytes)
    return hm.hexdigest()

def append_jsonl_secure(path: str, obj: dict):
    """
    Append one JSON object per line with:
      - size-based rotation
      - optional tamper-evident hash chain (_h with previous link _p)
    """
    _rotate_file_if_needed(path)

    # prepare
    prev_h = _last_chain_hmac(path)
    # attach signed fields non-destructively
    to_write = dict(obj)
    if LOG_HMAC_KEY_HEX:
        # NOTE: we compute HMAC over the line WITHOUT _h, then store _h and _p
        payload_bytes = json.dumps(to_write, ensure_ascii=False, separators=(",", ":")).encode("utf-8")
        h = _sign_line(payload_bytes, prev_h)
        to_write["_p"] = prev_h  # previous hash (or None)
        to_write["_h"] = h       # current hash (or None if key invalid)

    line = json.dumps(to_write, ensure_ascii=False)
    with open(path, "a", encoding="utf-8") as f:
        f.write(line + "\n")

def now_iso():
    return datetime.datetime.now(datetime.timezone.utc).astimezone().isoformat()

def ip_hash(ip):
    if not ip:
        return ""
    return hashlib.sha256(ip.encode("utf-8")).hexdigest()

def bot_tripwire():
    """
    Return a Flask Response to block if bot is suspected; otherwise return None.
    Uses a dynamic honeypot field name stored in cookie 'hp_field' if present,
    otherwise falls back to HONEYPOT_FIELD (env/default).
